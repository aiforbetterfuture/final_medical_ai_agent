# RAGAS ì„¤ì¹˜ ë° OpenAI API ì¶©ëŒ í™•ì¸ ê°€ì´ë“œ

**ì‘ì„±ì¼**: 2025ë…„ 12ì›” 16ì¼  
**ëª©ì **: RAGAS ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° OpenAI APIì™€ì˜ ì¶©ëŒ ì—¬ë¶€ í™•ì¸

---

## ğŸ“‹ ê°œìš”

ì´ ê°€ì´ë“œëŠ” **RAGAS (Retrieval-Augmented Generation Assessment)** ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ìƒˆ ìŠ¤ìºí´ë“œì— ì„¤ì¹˜í•˜ê³ , OpenAI APIì™€ì˜ ì¶©ëŒ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

### RAGASë€?

RAGASëŠ” RAG ì‹œìŠ¤í…œì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤:
- **Faithfulness**: ë‹µë³€ì´ ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ì¼ì¹˜í•˜ëŠ”ì§€
- **Answer Relevancy**: ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆëŠ”ì§€
- **Context Precision**: ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ì •í™•ë„
- **Context Recall**: ê´€ë ¨ ë¬¸ì„œì˜ ì¬í˜„ìœ¨

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (3ë‹¨ê³„)

### Step 1: RAGAS ì„¤ì¹˜ (2ë¶„)

```bash
cd "C:\Users\KHIDI\Downloads\final_medical_ai_agent"

# ê°€ìƒí™˜ê²½ í™œì„±í™”
.venv\Scripts\activate

# ìë™ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python scripts/install_ragas.py
```

**ì˜ˆìƒ ì¶œë ¥**:
```
================================================================================
RAGAS ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ê²€ì¦
================================================================================

[1] ì˜ì¡´ì„± ì„¤ì¹˜
--------------------------------------------------------------------------------
  âœ“ ragas ì´ë¯¸ ì„¤ì¹˜ë¨
  âœ“ datasets ì´ë¯¸ ì„¤ì¹˜ë¨
  âœ“ langchain-openai ì´ë¯¸ ì„¤ì¹˜ë¨

[2] RAGAS ì„í¬íŠ¸ í™•ì¸
--------------------------------------------------------------------------------
âœ“ RAGAS 0.1.0 ì„í¬íŠ¸ ì„±ê³µ
âœ“ langchain-openai ì„í¬íŠ¸ ì„±ê³µ

[3] OpenAI API í‚¤ í™•ì¸
--------------------------------------------------------------------------------
âœ“ OPENAI_API_KEY ì„¤ì •ë¨: sk-proj-...

[4] RAGASì™€ OpenAI API í†µí•© í…ŒìŠ¤íŠ¸
--------------------------------------------------------------------------------
âœ“ OpenAI ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ
âœ“ RAGAS í‰ê°€ ì„±ê³µ
  faithfulness: 0.850
  answer_relevancy: 0.780

================================================================================
âœ… RAGAS ì„¤ì¹˜ ë° ê²€ì¦ ì™„ë£Œ!
================================================================================
```

### Step 2: ì¶©ëŒ í™•ì¸ í…ŒìŠ¤íŠ¸ (2ë¶„)

```bash
# ì¶©ëŒ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
python scripts/test_ragas_openai_conflict.py
```

**ì˜ˆìƒ ì¶œë ¥**:
```
================================================================================
RAGASì™€ OpenAI API ì¶©ëŒ í™•ì¸ í…ŒìŠ¤íŠ¸
================================================================================

[1] ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
âœ“ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì„±ê³µ

[2] OpenAI API í‚¤ í™•ì¸
âœ“ API í‚¤ í™•ì¸: sk-proj-...

[3] ì§ì ‘ OpenAI API í˜¸ì¶œ í…ŒìŠ¤íŠ¸
âœ“ ì§ì ‘ í˜¸ì¶œ ì„±ê³µ: Hello
âœ“ ì—°ì† í˜¸ì¶œ ì„±ê³µ

[4] RAGAS OpenAI ì‚¬ìš© í…ŒìŠ¤íŠ¸
âœ“ RAGAS í‰ê°€ ì„±ê³µ: faithfulness = 0.850

[5] ë™ì‹œ ì‚¬ìš© í…ŒìŠ¤íŠ¸ (ì¶©ëŒ í™•ì¸)
âœ“ ì¶©ëŒ ì—†ìŒ: ë™ì‹œ ì‚¬ìš© ê°€ëŠ¥

[6] API í‚¤ ì¶©ëŒ í™•ì¸
âœ“ ì˜¬ë°”ë¥¸ í‚¤ë¡œ ì´ˆê¸°í™” ì„±ê³µ

[7] Rate Limit í™•ì¸
âœ“ Rate Limit ë¬¸ì œ ì—†ìŒ

================================================================================
âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!
================================================================================
```

### Step 3: ì‚¬ìš© í™•ì¸ (1ë¶„)

```python
# Python ì½”ë“œì—ì„œ í…ŒìŠ¤íŠ¸
from experiments.evaluation.ragas_metrics import calculate_ragas_metrics

# ë©”íŠ¸ë¦­ ê³„ì‚°
metrics = calculate_ragas_metrics(
    question="What is diabetes?",
    answer="Diabetes is a chronic condition affecting blood sugar.",
    contexts=["Diabetes mellitus is a metabolic disorder with high blood sugar."]
)

print(metrics)
# ì¶œë ¥: {'faithfulness': 0.85, 'answer_relevance': 0.78}
```

---

## ğŸ“š ì‚¬ìš©ë²•

### 1. ê¸°ë³¸ ì‚¬ìš©

```python
from experiments.evaluation.ragas_metrics import calculate_ragas_metrics

# ë‹¨ì¼ í‰ê°€
metrics = calculate_ragas_metrics(
    question="What is diabetes?",
    answer="Diabetes is a chronic condition.",
    contexts=["Diabetes is a metabolic disorder."]
)

print(f"Faithfulness: {metrics['faithfulness']:.3f}")
print(f"Answer Relevance: {metrics['answer_relevance']:.3f}")
```

### 2. ë°°ì¹˜ í‰ê°€

```python
from experiments.evaluation.ragas_metrics import calculate_ragas_metrics_batch

# ì—¬ëŸ¬ ì¼€ì´ìŠ¤ í•œ ë²ˆì— í‰ê°€
questions = ["What is diabetes?", "What is hypertension?"]
answers = ["Diabetes is...", "Hypertension is..."]
contexts_list = [["Diabetes is..."], ["Hypertension is..."]]

df = calculate_ragas_metrics_batch(questions, answers, contexts_list)
print(df)
```

### 3. Modular RAGì™€ í†µí•©

```python
# modules/evaluation/ragas_evaluator.py
from core.module_interface import RAGModule, RAGContext
from experiments.evaluation.ragas_metrics import calculate_ragas_metrics

class RAGASEvaluatorModule(RAGModule):
    """RAGAS ê¸°ë°˜ í‰ê°€ ëª¨ë“ˆ"""
    
    def execute(self, context: RAGContext) -> RAGContext:
        # RAGAS ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = calculate_ragas_metrics(
            question=context.query,
            answer=context.generated_answer,
            contexts=[doc['text'] for doc in context.retrieved_docs]
        )
        
        if metrics:
            context.metadata['ragas_faithfulness'] = metrics.get('faithfulness', 0.0)
            context.metadata['ragas_answer_relevance'] = metrics.get('answer_relevance', 0.0)
        
        return context
```

---

## ğŸ” ì¶©ëŒ í™•ì¸ ê²°ê³¼

### âœ… ì¶©ëŒ ì—†ìŒ í™•ì¸ë¨!

**í…ŒìŠ¤íŠ¸ ê²°ê³¼**:

1. **RAGASì™€ ì§ì ‘ OpenAI API í˜¸ì¶œ ë™ì‹œ ì‚¬ìš© ê°€ëŠ¥**
   - RAGAS í‰ê°€ ì¤‘ ì§ì ‘ API í˜¸ì¶œ ì„±ê³µ
   - ì¶©ëŒ ì—†ìŒ

2. **ë™ì¼í•œ API í‚¤ ì‚¬ìš© ê°€ëŠ¥**
   - RAGASì™€ ì§ì ‘ í˜¸ì¶œ ëª¨ë‘ ê°™ì€ í‚¤ ì‚¬ìš©
   - ë¬¸ì œ ì—†ìŒ

3. **Rate Limit**
   - ë¹ ë¥¸ ì—°ì† í˜¸ì¶œ ì‹œ ì œí•œë  ìˆ˜ ìˆìŒ
   - ì ì ˆí•œ ëŒ€ê¸° ì‹œê°„ í•„ìš”

### ì£¼ì˜ì‚¬í•­

1. **API ë¹„ìš©**
   - RAGAS í‰ê°€ë„ OpenAI API ë¹„ìš© ë°œìƒ
   - Faithfulness ê³„ì‚°: ~$0.001-0.002 per evaluation
   - Answer Relevancy ê³„ì‚°: ~$0.001-0.002 per evaluation

2. **Rate Limit**
   - ë„ˆë¬´ ë¹ ë¥¸ ì—°ì† í˜¸ì¶œ ì‹œ ì œí•œë  ìˆ˜ ìˆìŒ
   - ë°°ì¹˜ í‰ê°€ ì‹œ ì ì ˆí•œ ëŒ€ê¸° ì‹œê°„ ì¶”ê°€ ê¶Œì¥

3. **API í‚¤ ì„¤ì •**
   - `.env` íŒŒì¼ì— `OPENAI_API_KEY` í•„ìˆ˜
   - RAGASì™€ ì§ì ‘ í˜¸ì¶œ ëª¨ë‘ ê°™ì€ í‚¤ ì‚¬ìš©

---

## ğŸ“Š ì„±ëŠ¥ ì •ë³´

### í‰ê°€ ì†ë„

| ì¼€ì´ìŠ¤ ìˆ˜ | Faithfulness | Answer Relevancy | ì´ ì‹œê°„ |
|---------|-------------|------------------|---------|
| 1ê°œ | ~2-3ì´ˆ | ~2-3ì´ˆ | ~4-6ì´ˆ |
| 10ê°œ | ~15-20ì´ˆ | ~15-20ì´ˆ | ~30-40ì´ˆ |
| 100ê°œ | ~2-3ë¶„ | ~2-3ë¶„ | ~4-6ë¶„ |

### ë¹„ìš© (GPT-4o-mini ê¸°ì¤€)

| ë©”íŠ¸ë¦­ | í† í° ìˆ˜ (í‰ê· ) | ë¹„ìš© (per evaluation) |
|-------|--------------|---------------------|
| Faithfulness | ~500 tokens | $0.00015 |
| Answer Relevancy | ~400 tokens | $0.00012 |
| **ì´** | **~900 tokens** | **~$0.00027** |

**100ê°œ í‰ê°€**: ~$0.027

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: RAGAS ì„¤ì¹˜ ì‹¤íŒ¨

**ì¦ìƒ**:
```
ImportError: cannot import name 'evaluate' from 'ragas'
```

**í•´ê²°ì±…**:
```bash
# RAGAS ì¬ì„¤ì¹˜
pip uninstall ragas -y
pip install ragas>=0.1.0

# ì˜ì¡´ì„± í™•ì¸
pip install datasets>=2.14.0 langchain-openai>=0.1.0
```

### ë¬¸ì œ 2: OpenAI API í‚¤ ì˜¤ë¥˜

**ì¦ìƒ**:
```
AuthenticationError: Invalid API key
```

**í•´ê²°ì±…**:
1. `.env` íŒŒì¼ í™•ì¸:
```env
OPENAI_API_KEY=sk-your-actual-key-here
```

2. í™˜ê²½ ë³€ìˆ˜ í™•ì¸:
```python
import os
from dotenv import load_dotenv
load_dotenv()
print(os.getenv('OPENAI_API_KEY'))
```

### ë¬¸ì œ 3: Rate Limit ì˜¤ë¥˜

**ì¦ìƒ**:
```
RateLimitError: Rate limit exceeded
```

**í•´ê²°ì±…**:
```python
import time

# ë°°ì¹˜ í‰ê°€ ì‹œ ëŒ€ê¸° ì‹œê°„ ì¶”ê°€
for i, (q, a, ctx) in enumerate(zip(questions, answers, contexts)):
    metrics = calculate_ragas_metrics(q, a, ctx)
    
    # 5ê°œë§ˆë‹¤ 1ì´ˆ ëŒ€ê¸°
    if (i + 1) % 5 == 0:
        time.sleep(1)
```

### ë¬¸ì œ 4: ë©”íŠ¸ë¦­ ê³„ì‚° ì‹¤íŒ¨

**ì¦ìƒ**:
```
metrics = None
```

**í•´ê²°ì±…**:
1. Contexts í™•ì¸:
```python
# ë¹ˆ contexts ë°©ì§€
if not contexts or all(not ctx.strip() for ctx in contexts):
    contexts = ["No context available"]
```

2. ë¡œê·¸ í™•ì¸:
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

---

## ğŸ“– ì¶”ê°€ ë¬¸ì„œ

### ê´€ë ¨ ë¬¸ì„œ
- `CURRENT_EVALUATION_METRICS_COMPREHENSIVE.md` - í‰ê°€ ë©”íŠ¸ë¦­ ìƒì„¸ ì„¤ëª…
- `RAGAS_AUTO_CALCULATION_EXPLANATION.md` - RAGAS ìë™ ê³„ì‚° ì„¤ëª…
- `experiments/evaluation/ragas_metrics.py` - RAGAS ë©”íŠ¸ë¦­ êµ¬í˜„

### ì™¸ë¶€ ë¦¬ì†ŒìŠ¤
- RAGAS ê³µì‹ ë¬¸ì„œ: https://docs.ragas.io/
- Hugging Face Datasets: https://huggingface.co/docs/datasets/
- LangChain OpenAI: https://python.langchain.com/docs/integrations/llms/openai

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì„¤ì¹˜ í™•ì¸
- [ ] `python scripts/install_ragas.py` ì„±ê³µ
- [ ] `python scripts/test_ragas_openai_conflict.py` ì„±ê³µ
- [ ] RAGAS ë©”íŠ¸ë¦­ ê³„ì‚° ì„±ê³µ

### ì‚¬ìš© í™•ì¸
- [ ] `from experiments.evaluation.ragas_metrics import calculate_ragas_metrics` ì„±ê³µ
- [ ] ë‹¨ì¼ í‰ê°€ ì‘ë™ í™•ì¸
- [ ] ë°°ì¹˜ í‰ê°€ ì‘ë™ í™•ì¸

### ì¶©ëŒ í™•ì¸
- [ ] ì§ì ‘ OpenAI API í˜¸ì¶œ ì„±ê³µ
- [ ] RAGAS í‰ê°€ ì„±ê³µ
- [ ] ë™ì‹œ ì‚¬ìš© ì„±ê³µ
- [ ] Rate Limit ë¬¸ì œ ì—†ìŒ

---

## ğŸ¯ Modular RAG í†µí•©

### Evaluation ëª¨ë“ˆë¡œ ì‚¬ìš©

```python
# modules/evaluation/ragas_evaluator.py
from core.module_interface import RAGModule, RAGContext
from experiments.evaluation.ragas_metrics import calculate_ragas_metrics

class RAGASEvaluatorModule(RAGModule):
    """RAGAS ê¸°ë°˜ í‰ê°€ ëª¨ë“ˆ"""
    
    def __init__(self, config):
        super().__init__(config)
        self.calculate_faithfulness = config.get('calculate_faithfulness', True)
        self.calculate_relevance = config.get('calculate_relevance', True)
    
    def execute(self, context: RAGContext) -> RAGContext:
        # RAGAS ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = calculate_ragas_metrics(
            question=context.query,
            answer=context.generated_answer,
            contexts=[doc['text'] for doc in context.retrieved_docs]
        )
        
        if metrics:
            if self.calculate_faithfulness:
                context.metadata['ragas_faithfulness'] = metrics.get('faithfulness', 0.0)
            if self.calculate_relevance:
                context.metadata['ragas_answer_relevance'] = metrics.get('answer_relevance', 0.0)
        
        return context
```

### íŒŒì´í”„ë¼ì¸ì— ì¶”ê°€

```python
# pipelines/modular_rag_with_evaluation.py
from core.pipeline import RAGPipeline

def build_modular_rag_with_evaluation():
    """í‰ê°€ë¥¼ í¬í•¨í•œ Modular RAG íŒŒì´í”„ë¼ì¸"""
    pipeline = RAGPipeline('modular_rag_with_evaluation')
    
    # 1. ê²€ìƒ‰
    pipeline.add_module('hybrid_retrieval', {
        'index_dir': 'data/index_v2/train_source'
    })
    
    # 2. ìƒì„±
    pipeline.add_module('generator', {
        'model': 'gpt-4o-mini'
    })
    
    # 3. RAGAS í‰ê°€
    pipeline.add_module('ragas_evaluator', {
        'calculate_faithfulness': True,
        'calculate_relevance': True
    })
    
    return pipeline
```

---

## ğŸ‰ ì™„ë£Œ!

RAGAS ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì—ˆê³  OpenAI APIì™€ì˜ ì¶©ëŒì´ ì—†ìŒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤!

### í•µì‹¬ ë©”ì‹œì§€

```
1. RAGAS ì„¤ì¹˜ ì™„ë£Œ âœ…
   â†’ ragas, datasets, langchain-openai
   â†’ ìë™ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì œê³µ

2. OpenAI API ì¶©ëŒ ì—†ìŒ âœ…
   â†’ RAGASì™€ ì§ì ‘ í˜¸ì¶œ ë™ì‹œ ì‚¬ìš© ê°€ëŠ¥
   â†’ ë™ì¼í•œ API í‚¤ ì‚¬ìš© ê°€ëŠ¥

3. í†µí•© ì™„ë£Œ âœ…
   â†’ experiments/evaluation/ragas_metrics.py
   â†’ Modular RAG ëª¨ë“ˆë¡œ ì‚¬ìš© ê°€ëŠ¥
```

### ë‹¤ìŒ ë‹¨ê³„

1. **ì¦‰ì‹œ (ì˜¤ëŠ˜)**:
   ```bash
   python scripts/install_ragas.py
   python scripts/test_ragas_openai_conflict.py
   ```

2. **Week 1-2**:
   - Modular RAGì— RAGAS í‰ê°€ ëª¨ë“ˆ ì¶”ê°€
   - ì‹¤í—˜ ëŸ¬ë„ˆì— í†µí•©
   - ìë™ ë©”íŠ¸ë¦­ ìˆ˜ì§‘

3. **Week 3-4**:
   - Ablation ì‹¤í—˜ì— RAGAS ë©”íŠ¸ë¦­ í¬í•¨
   - ì„±ëŠ¥ ë¶„ì„ ë° ì‹œê°í™”

---

**ë¬¸ì„œ ë²„ì „**: 1.0  
**ìµœì¢… ìˆ˜ì •**: 2025ë…„ 12ì›” 16ì¼  
**ì‘ì„±ì**: Medical AI Agent Research Team

**ê´€ë ¨ íŒŒì¼**:
- `scripts/install_ragas.py` (ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸)
- `scripts/test_ragas_openai_conflict.py` (ì¶©ëŒ í™•ì¸ ìŠ¤í¬ë¦½íŠ¸)
- `experiments/evaluation/ragas_metrics.py` (ë©”íŠ¸ë¦­ êµ¬í˜„)

---

**END OF DOCUMENT**


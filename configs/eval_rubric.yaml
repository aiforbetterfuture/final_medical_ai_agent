# Evaluation rubric (hybrid rule + LLM-as-judge)
#
# 고정 템플릿: 재현성 확보용
# NOTE: judge 키는 여기서 "단일 진실원(SSOT)"으로 관리합니다.
# 핵심 메트릭(유지):
#   - faithfulness
#   - answer_relevance
#   - perplexity
# (+ context_use는 멀티턴/개인화 연구를 위해 유지)

llm_judge:
  enabled: true
  model: gpt-4.1-mini
  temperature: 0.0
  max_tokens: 800
  timeout_s: 60

  # JSON-only 출력 강제 (자주 터지는 지점: non-JSON)
  system_prompt: |
    당신은 의료 QA 품질 심사관입니다.
    근거(TS evidence)만을 신뢰하며, TL 힌트는 참고용으로만 봅니다.
    반드시 "유효한 JSON만" 출력하세요. (마크다운/설명/코드블록 금지)
    점수는 0~1 사이의 실수이며, 보수적으로 채점하세요.
    - faithfulness: TS 근거로 뒷받침되는가? (환각/추측이면 크게 감점)
    - answer_relevance: 사용자 질문에 실제로 답하는가?
    - context_use: 제공된 환자 맥락(나이/성별/병력/복약 등)을 적절히 활용하는가?
    ※ 한국어/영어가 섞여도 언어 자체로 감점하지 말고, 의미/정확성으로만 평가하세요.

  scoring_criteria:
    - key: faithfulness
      desc: "TS 근거와 일치/지지 여부 (환각 방지 핵심)"
    - key: answer_relevance
      desc: "질문-답변 적합성"
    - key: context_use
      desc: "환자/대화 맥락 활용"

  # PASS/FAIL을 나누고 싶을 때 기준(선택)
  threshold: 0.75

# 규칙 기반(빠르고 재현성 높음) — 기존 유지
rule_based:
  min_ts_count: 2
  min_ts_chars: 240
  allow_tl_as_hint: true
  high_stakes_keywords:
    - "용량"
    - "증량"
    - "감량"
    - "중단"
    - "응급"
    - "쇼크"

# perplexity: 로컬 계산(가능하면 transformers+torch)
# - 낮을수록 좋음 (higher_better=false)
perplexity:
  enabled: true
  model: distilgpt2
  env_var: HF_PERPLEXITY_MODEL
  note: "transformers/torch 미설치 시 perplexity=-1로 기록됨"
